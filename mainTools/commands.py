import os
import json
import subprocess
import re
import base64
import shutil
from datetime import datetime
from urllib import request, error, parse as urlparse
from utility import parse_markdown_metadata, read_markdowns, find_first_image, read_file_safe
from path_utils import get_base_path, get_posts_path, get_assets_path
from cryptography.hazmat.primitives.ciphers.aead import AESGCM
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC


class Command:
    description = "Base command class"

    def execute(self):
        raise NotImplementedError("You should implement this method.")


class CryptoEncryptor:
    """æ–‡ç« åŠ å¯†å·¥å…·ç±» - ä½¿ç”¨ AES-GCM åŠ å¯†ç®—æ³•"""

    @staticmethod
    def derive_key(password: str, salt: bytes = None) -> tuple:
        """ä»å¯†ç æ´¾ç”ŸåŠ å¯†å¯†é’¥"""
        if salt is None:
            salt = os.urandom(16)

        kdf = PBKDF2HMAC(
            algorithm=hashes.SHA256(),
            length=32,
            salt=salt,
            iterations=100000,
        )
        key = kdf.derive(password.encode('utf-8'))
        return key, salt

    @staticmethod
    def encrypt_file(file_path: str, password: str, output_path: str) -> dict:
        """åŠ å¯†æ–‡ä»¶ï¼ˆåªåŠ å¯†æ–‡ç« å†…å®¹ï¼Œä¿ç•™ metadata æ˜æ–‡ï¼‰

        Args:
            file_path: æºæ–‡ä»¶è·¯å¾„
            password: åŠ å¯†å¯†ç 
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Returns:
            dict: {'success': bool, 'message': str, 'salt': str, 'nonce': str}
        """
        try:
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # åˆ†ç¦» metadata å’Œ body
            metadata_regex = r'^---\n([\s\S]*?)\n---\n([\s\S]*)$'
            match = re.search(metadata_regex, content)

            if match:
                metadata_text = match.group(1)
                body_text = match.group(2)
            else:
                # å¦‚æœæ²¡æœ‰ metadataï¼Œæ•´ä¸ªå†…å®¹ä½œä¸º body
                metadata_text = ''
                body_text = content

            # æ´¾ç”Ÿå¯†é’¥
            key, salt = CryptoEncryptor.derive_key(password)

            # åˆ›å»º AES-GCM åŠ å¯†å™¨
            aesgcm = AESGCM(key)
            nonce = os.urandom(12)  # GCM æ¨¡å¼æ¨è 12 å­—èŠ‚

            # åªåŠ å¯† body éƒ¨åˆ†
            body_bytes = body_text.encode('utf-8')
            ciphertext = aesgcm.encrypt(nonce, body_bytes, None)

            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(output_path), exist_ok=True)

            # å†™å…¥åŠ å¯†æ–‡ä»¶ï¼šmetadataï¼ˆæ˜æ–‡ï¼‰+ åˆ†éš”ç¬¦ + salt + nonce + ciphertext
            with open(output_path, 'w', encoding='utf-8') as f:
                # å†™å…¥ metadataï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if metadata_text:
                    f.write('---\n')
                    f.write(metadata_text)
                    f.write('\n---\n')

                # å†™å…¥åŠ å¯†æ ‡è®°å’ŒåŠ å¯†æ•°æ®ï¼ˆbase64ç¼–ç ï¼‰
                f.write('<!-- ENCRYPTED CONTENT -->\n')
                encrypted_data = salt + nonce + ciphertext
                f.write(base64.b64encode(encrypted_data).decode('utf-8'))

            return {
                'success': True,
                'message': f'åŠ å¯†æˆåŠŸ: {os.path.basename(file_path)}',
                'salt': base64.b64encode(salt).decode('utf-8'),
                'nonce': base64.b64encode(nonce).decode('utf-8')
            }

        except Exception as e:
            return {
                'success': False,
                'message': f'åŠ å¯†å¤±è´¥: {str(e)}'
            }

    @staticmethod
    def decrypt_file(file_path: str, password: str, output_path: str) -> dict:
        """è§£å¯†æ–‡ä»¶ï¼ˆè§£å¯†æ–‡ç« å†…å®¹ï¼Œä¿ç•™ metadataï¼‰

        Args:
            file_path: åŠ å¯†æ–‡ä»¶è·¯å¾„
            password: è§£å¯†å¯†ç 
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Returns:
            dict: {'success': bool, 'message': str}
        """
        try:
            # è¯»å–åŠ å¯†æ–‡ä»¶
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # åˆ†ç¦» metadata å’ŒåŠ å¯†æ•°æ®
            metadata_regex = r'^---\n([\s\S]*?)\n---\n'
            match = re.search(metadata_regex, content)

            if match:
                metadata_text = match.group(1)
                # æå–åŠ å¯†æ•°æ®ï¼ˆå»æ‰æ³¨é‡Šè¡Œï¼‰
                encrypted_part = content[match.end():]
                encrypted_part = encrypted_part.replace(
                    '<!-- ENCRYPTED CONTENT -->\n', '').strip()
            else:
                metadata_text = ''
                encrypted_part = content.replace(
                    '<!-- ENCRYPTED CONTENT -->\n', '').strip()

            # Base64 è§£ç åŠ å¯†æ•°æ®
            encrypted_data = base64.b64decode(encrypted_part)

            # è§£æåŠ å¯†æ•°æ®ï¼šsalt + nonce + ciphertext
            if len(encrypted_data) < 28:
                raise Exception('åŠ å¯†æ•°æ®æ ¼å¼é”™è¯¯')

            salt = encrypted_data[:16]
            nonce = encrypted_data[16:28]
            ciphertext = encrypted_data[28:]

            # æ´¾ç”Ÿå¯†é’¥
            key, _ = CryptoEncryptor.derive_key(password, salt)

            # è§£å¯†
            aesgcm = AESGCM(key)
            body_bytes = aesgcm.decrypt(nonce, ciphertext, None)
            body_text = body_bytes.decode('utf-8')

            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(output_path), exist_ok=True)

            # é‡æ–°ç»„åˆ metadata å’Œ body
            with open(output_path, 'w', encoding='utf-8') as f:
                if metadata_text:
                    f.write('---\n')
                    f.write(metadata_text)
                    f.write('\n---\n')
                f.write(body_text)

            return {
                'success': True,
                'message': f'è§£å¯†æˆåŠŸ: {os.path.basename(file_path)}'
            }

        except Exception as e:
            return {
                'success': False,
                'message': f'è§£å¯†å¤±è´¥: {str(e)}'
            }


class InitBlog(Command):
    description = "Initializes the blog structure with necessary directories and a sample post."

    def _check_command(self, command):
        """æ£€æŸ¥å‘½ä»¤æ˜¯å¦å­˜åœ¨"""
        try:
            result = subprocess.run(
                f'{command} --version',
                shell=True,
                capture_output=True,
                text=True,
                encoding='utf-8',
                errors='replace'
            )
            return result.returncode == 0
        except:
            return False

    def _install_git(self):
        """å®‰è£… Git"""
        print("[ç¯å¢ƒæ£€æŸ¥] Git æœªå®‰è£…ï¼Œæ­£åœ¨ä¸‹è½½å®‰è£…...")
        
        if os.name == 'nt':  # Windows
            # ä¸‹è½½ Git å®‰è£…å™¨
            git_installer_url = "https://github.com/git-for-windows/git/releases/download/v2.43.0.windows.1/Git-2.43.0-64-bit.exe"
            installer_path = os.path.join(os.environ.get('TEMP', '.'), 'git_installer.exe')
            
            try:
                print(f"[Gitå®‰è£…] æ­£åœ¨ä¸‹è½½ Git å®‰è£…å™¨...")
                request.urlretrieve(git_installer_url, installer_path)
                
                print(f"[Gitå®‰è£…] æ­£åœ¨å®‰è£… Gitï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
                # é™é»˜å®‰è£…
                result = subprocess.run(
                    [installer_path, '/VERYSILENT', '/NORESTART'],
                    check=True
                )
                
                # æ¸…ç†å®‰è£…å™¨
                os.remove(installer_path)
                
                print("[Gitå®‰è£…] Git å®‰è£…å®Œæˆï¼")
                return True
            except Exception as e:
                print(f"[Gitå®‰è£…] è‡ªåŠ¨å®‰è£…å¤±è´¥: {e}")
                print("[Gitå®‰è£…] è¯·æ‰‹åŠ¨ä» https://git-scm.com/download/win ä¸‹è½½å¹¶å®‰è£… Git")
                return False
        else:
            print("[Gitå®‰è£…] è¯·æ‰‹åŠ¨å®‰è£… Git:")
            print("  Ubuntu/Debian: sudo apt-get install git")
            print("  macOS: brew install git")
            return False

    def _install_nodejs(self):
        """å®‰è£… Node.js"""
        print("[ç¯å¢ƒæ£€æŸ¥] Node.js æœªå®‰è£…ï¼Œæ­£åœ¨ä¸‹è½½å®‰è£…...")
        
        if os.name == 'nt':  # Windows
            # ä¸‹è½½ Node.js å®‰è£…å™¨
            nodejs_installer_url = "https://nodejs.org/dist/v20.11.0/node-v20.11.0-x64.msi"
            installer_path = os.path.join(os.environ.get('TEMP', '.'), 'nodejs_installer.msi')
            
            try:
                print(f"[Node.jså®‰è£…] æ­£åœ¨ä¸‹è½½ Node.js å®‰è£…å™¨...")
                request.urlretrieve(nodejs_installer_url, installer_path)
                
                print(f"[Node.jså®‰è£…] æ­£åœ¨å®‰è£… Node.jsï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
                # é™é»˜å®‰è£…
                result = subprocess.run(
                    ['msiexec', '/i', installer_path, '/quiet', '/norestart'],
                    check=True
                )
                
                # æ¸…ç†å®‰è£…å™¨
                os.remove(installer_path)
                
                print("[Node.jså®‰è£…] Node.js å®‰è£…å®Œæˆï¼")
                return True
            except Exception as e:
                print(f"[Node.jså®‰è£…] è‡ªåŠ¨å®‰è£…å¤±è´¥: {e}")
                print("[Node.jså®‰è£…] è¯·æ‰‹åŠ¨ä» https://nodejs.org/ ä¸‹è½½å¹¶å®‰è£… Node.js")
                return False
        else:
            print("[Node.jså®‰è£…] è¯·æ‰‹åŠ¨å®‰è£… Node.js:")
            print("  Ubuntu/Debian: sudo apt-get install nodejs npm")
            print("  macOS: brew install node")
            return False

    def execute(self):
        base_path = get_base_path()
        
        # 1. æ£€æŸ¥ç¯å¢ƒ
        print("[ç¯å¢ƒæ£€æŸ¥] å¼€å§‹æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒ...")
        
        # æ£€æŸ¥ Git
        if not self._check_command('git'):
            print("[ç¯å¢ƒæ£€æŸ¥] âœ— Git æœªå®‰è£…")
            if not self._install_git():
                raise Exception("Git å®‰è£…å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å®‰è£…åé‡è¯•")
        else:
            print("[ç¯å¢ƒæ£€æŸ¥] âœ“ Git å·²å®‰è£…")
        
        # æ£€æŸ¥ Node.js
        if not self._check_command('node'):
            print("[ç¯å¢ƒæ£€æŸ¥] âœ— Node.js æœªå®‰è£…")
            if not self._install_nodejs():
                raise Exception("Node.js å®‰è£…å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å®‰è£…åé‡è¯•")
        else:
            print("[ç¯å¢ƒæ£€æŸ¥] âœ“ Node.js å·²å®‰è£…")
        
        # æ£€æŸ¥ npm
        if not self._check_command('npm'):
            print("[ç¯å¢ƒæ£€æŸ¥] âœ— npm æœªå®‰è£…")
            raise Exception("npm æœªå®‰è£…ï¼Œè¯·é‡æ–°å®‰è£… Node.js")
        else:
            print("[ç¯å¢ƒæ£€æŸ¥] âœ“ npm å·²å®‰è£…")
        
        # 2. æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯ Git ä»“åº“
        git_dir = os.path.join(base_path, '.git')
        if os.path.exists(git_dir):
            print("[åˆå§‹åŒ–] æ£€æµ‹åˆ°å·²å­˜åœ¨çš„ Git ä»“åº“ï¼Œè·³è¿‡å…‹éš†")
        else:
            # 3. ä» GitHub æ‹‰å–ä»£ç 
            print("[åˆå§‹åŒ–] æ­£åœ¨ä» GitHub æ‹‰å– KMBlog æ¡†æ¶...")
            try:
                # ä½¿ç”¨ç”¨æˆ·çš„ä¸´æ—¶ç›®å½•
                import tempfile
                temp_base = tempfile.gettempdir()
                temp_dir = os.path.join(temp_base, f'kmblog_init_{os.getpid()}')
                
                # ç¡®ä¿ä¸´æ—¶ç›®å½•ä¸å­˜åœ¨
                if os.path.exists(temp_dir):
                    try:
                        shutil.rmtree(temp_dir)
                    except:
                        # å¦‚æœåˆ é™¤å¤±è´¥ï¼Œä½¿ç”¨å¦ä¸€ä¸ªåç§°
                        import time
                        temp_dir = os.path.join(temp_base, f'kmblog_init_{os.getpid()}_{int(time.time())}')
                
                print(f"[åˆå§‹åŒ–] ä¸´æ—¶ç›®å½•: {temp_dir}")
                
                # å…‹éš†ä»“åº“åˆ°ä¸´æ—¶ç›®å½•
                result = subprocess.run(
                    ['git', 'clone', '--depth', '1', 'https://github.com/iiishop/KMBlog.git', temp_dir],
                    capture_output=True,
                    text=True,
                    encoding='utf-8',
                    errors='replace',
                    check=True
                )
                print("[åˆå§‹åŒ–] âœ“ ä»£ç æ‹‰å–å®Œæˆ")
                
                # ç§»åŠ¨æ–‡ä»¶åˆ°å½“å‰ç›®å½•
                print("[åˆå§‹åŒ–] æ­£åœ¨å¤åˆ¶æ–‡ä»¶...")
                
                # è·å–æ‰€æœ‰éœ€è¦å¤åˆ¶çš„æ–‡ä»¶å’Œç›®å½•
                items_to_copy = []
                for item in os.listdir(temp_dir):
                    if item == '.git':
                        continue  # è·³è¿‡ .git ç›®å½•
                    items_to_copy.append(item)
                
                # å¤åˆ¶æ–‡ä»¶
                copied_count = 0
                for item in items_to_copy:
                    src = os.path.join(temp_dir, item)
                    dst = os.path.join(base_path, item)
                    
                    try:
                        # å¦‚æœç›®æ ‡å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
                        if os.path.exists(dst):
                            if os.path.isdir(dst):
                                shutil.rmtree(dst)
                            else:
                                os.remove(dst)
                        
                        # å¤åˆ¶
                        if os.path.isdir(src):
                            shutil.copytree(src, dst)
                        else:
                            shutil.copy2(src, dst)
                        
                        copied_count += 1
                        print(f"[åˆå§‹åŒ–] å¤åˆ¶: {item}")
                    except Exception as e:
                        print(f"[åˆå§‹åŒ–] è­¦å‘Š: å¤åˆ¶ {item} å¤±è´¥: {e}")
                
                print(f"[åˆå§‹åŒ–] âœ“ æ–‡ä»¶å¤åˆ¶å®Œæˆ ({copied_count}/{len(items_to_copy)} ä¸ªé¡¹ç›®)")
                
                # æ¸…ç†ä¸´æ—¶ç›®å½•ï¼ˆä½¿ç”¨æ›´å¼ºå¤§çš„æ¸…ç†æœºåˆ¶ï¼‰
                print("[åˆå§‹åŒ–] æ­£åœ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
                cleanup_success = False
                
                try:
                    # æ–¹æ³•1: ä½¿ç”¨ shutil.rmtree çš„ onerror å›è°ƒå¤„ç†æƒé™é—®é¢˜
                    def handle_remove_readonly(func, path, exc):
                        """å¤„ç†åªè¯»æ–‡ä»¶çš„åˆ é™¤"""
                        import stat
                        if os.name == 'nt':
                            # Windows: ç§»é™¤åªè¯»å±æ€§
                            try:
                                os.chmod(path, stat.S_IWRITE)
                                func(path)
                            except:
                                pass
                        else:
                            # Unix: æ·»åŠ å†™æƒé™
                            try:
                                os.chmod(path, stat.S_IWUSR | stat.S_IRUSR)
                                func(path)
                            except:
                                pass
                    
                    shutil.rmtree(temp_dir, onerror=handle_remove_readonly)
                    
                    if not os.path.exists(temp_dir):
                        print("[åˆå§‹åŒ–] âœ“ ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ")
                        cleanup_success = True
                    
                except Exception as e:
                    print(f"[åˆå§‹åŒ–] æ–¹æ³•1æ¸…ç†å¤±è´¥: {e}")
                
                # æ–¹æ³•2: å¦‚æœæ–¹æ³•1å¤±è´¥ï¼Œåœ¨Windowsä¸Šä½¿ç”¨ rmdir /s /q å‘½ä»¤
                if not cleanup_success and os.name == 'nt' and os.path.exists(temp_dir):
                    try:
                        print("[åˆå§‹åŒ–] å°è¯•ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤æ¸…ç†...")
                        subprocess.run(
                            ['cmd', '/c', 'rmdir', '/s', '/q', temp_dir],
                            stdout=subprocess.DEVNULL,
                            stderr=subprocess.DEVNULL,
                            timeout=30
                        )
                        
                        if not os.path.exists(temp_dir):
                            print("[åˆå§‹åŒ–] âœ“ ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆï¼ˆä½¿ç”¨ç³»ç»Ÿå‘½ä»¤ï¼‰")
                            cleanup_success = True
                    except Exception as e:
                        print(f"[åˆå§‹åŒ–] æ–¹æ³•2æ¸…ç†å¤±è´¥: {e}")
                
                # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œç»™å‡ºè­¦å‘Šä½†ä¸é˜»æ­¢ç»§ç»­
                if not cleanup_success and os.path.exists(temp_dir):
                    print(f"[åˆå§‹åŒ–] è­¦å‘Š: ä¸´æ—¶æ–‡ä»¶æ¸…ç†å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨åˆ é™¤: {temp_dir}")
                    print("[åˆå§‹åŒ–] è¿™ä¸ä¼šå½±å“åšå®¢çš„æ­£å¸¸ä½¿ç”¨ï¼Œå¯ä»¥ç¨åæ‰‹åŠ¨åˆ é™¤è¯¥ç›®å½•")
                
            except subprocess.CalledProcessError as e:
                raise Exception(f"Git å…‹éš†å¤±è´¥: {e.stderr}")
            except Exception as e:
                raise Exception(f"ä»£ç æ‹‰å–å¤±è´¥: {str(e)}")
        
        # 4. å®‰è£…ä¾èµ–
        print("[åˆå§‹åŒ–] æ­£åœ¨å®‰è£… npm ä¾èµ–...")
        try:
            result = subprocess.run(
                'npm install',
                cwd=base_path,
                shell=True,
                capture_output=True,
                text=True,
                encoding='utf-8',
                errors='replace',
                check=True
            )
            print("[åˆå§‹åŒ–] âœ“ ä¾èµ–å®‰è£…å®Œæˆ")
        except subprocess.CalledProcessError as e:
            raise Exception(f"npm install å¤±è´¥: {e.stderr}")
        
        # 5. åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„
        posts_path = get_posts_path()
        markdowns_path = os.path.join(posts_path, 'Markdowns')
        images_path = os.path.join(posts_path, 'Images')
        
        os.makedirs(markdowns_path, exist_ok=True)
        os.makedirs(images_path, exist_ok=True)
        
        # 6. åˆ›å»ºç¤ºä¾‹æ–‡ç« ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        hello_world_path = os.path.join(markdowns_path, 'Helloworld.md')
        if not os.path.exists(hello_world_path):
            name = "Helloworld"
            date_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            metadata = f"""---
title: {name}
date: {date_str}
tags: 
- hello world
categories: 
pre: This is a sample post to demonstrate the blog structure.
img: 
---

# Hello KMBlog

Welcome to KMBlog! This is your first post.

## Getting Started

You can start writing your blog posts in Markdown format.

## Features

- ğŸ“ Markdown support
- ğŸ¨ Beautiful themes
- ğŸ“± Responsive design
- ğŸš€ Fast and lightweight

Happy blogging!
"""
            
            with open(hello_world_path, 'w', encoding='utf-8') as file:
                file.write(metadata)
            
            print(f"[åˆå§‹åŒ–] âœ“ åˆ›å»ºç¤ºä¾‹æ–‡ç« : {hello_world_path}")
        
        # 7. ç”Ÿæˆé…ç½®
        print("[åˆå§‹åŒ–] æ­£åœ¨ç”Ÿæˆé…ç½®æ–‡ä»¶...")
        output_command = Generate()
        output_result = output_command.execute()
        
        return f"""
âœ“ KMBlog åˆå§‹åŒ–å®Œæˆï¼

ç¯å¢ƒæ£€æŸ¥:
  âœ“ Git å·²å®‰è£…
  âœ“ Node.js å·²å®‰è£…
  âœ“ npm å·²å®‰è£…

åˆå§‹åŒ–æ­¥éª¤:
  âœ“ ä» GitHub æ‹‰å–ä»£ç 
  âœ“ å®‰è£… npm ä¾èµ–
  âœ“ åˆ›å»ºç›®å½•ç»“æ„
  âœ“ åˆ›å»ºç¤ºä¾‹æ–‡ç« 
  âœ“ ç”Ÿæˆé…ç½®æ–‡ä»¶

ä¸‹ä¸€æ­¥:
  1. è¿è¡Œ 'npm run dev' å¯åŠ¨å¼€å‘æœåŠ¡å™¨
  2. æˆ–è¿è¡Œ 'npm run build' æ„å»ºç”Ÿäº§ç‰ˆæœ¬

{output_result}
"""


class ShowPostsJson(Command):
    description = "Shows the posts directory structure in JSON format."

    def execute(self):
        base_path = os.path.abspath(
            os.path.join(os.path.dirname(__file__), '../'))
        posts_path = os.path.join(base_path, 'public/Posts')
        if not os.path.exists(posts_path):
            raise FileNotFoundError(
                f"No such file or directory: '{posts_path}'")

        result = {}
        current_id = 1  # åˆå§‹åŒ– ID è®¡æ•°å™¨

        markdowns_path = os.path.join(posts_path, 'Markdowns')
        if (os.path.exists(markdowns_path)):
            result['Markdowns'] = self._convert_to_relative_paths(
                read_markdowns(markdowns_path), current_id)
            current_id += len(result['Markdowns'])

        directories = [
            file for file in os.listdir(posts_path)
            if os.path.isdir(os.path.join(posts_path, file))
        ]

        for dir_name in directories:
            dir_path = os.path.join(posts_path, dir_name)
            if dir_name not in ['Markdowns', 'Images']:
                sub_result = {}
                markdowns_sub_path = dir_path
                stats = os.stat(dir_path)
                sub_result['date'] = datetime.fromtimestamp(
                    stats.st_ctime).strftime('%Y-%m-%d')
                if os.path.exists(markdowns_sub_path):
                    sub_result['Markdowns'] = self._convert_to_relative_paths(
                        read_markdowns(markdowns_sub_path), current_id)
                    current_id += len(sub_result['Markdowns'])

                image = find_first_image(dir_path)
                if image:
                    sub_result['image'] = self._convert_to_relative_path(image)

                result[dir_name] = sub_result

        return result

    def _convert_to_relative_paths(self, paths, start_id, base_path='/public'):
        return [{'id': start_id + i, 'path': self._convert_to_relative_path(path, base_path)} for i, path in enumerate(paths)]

    def _convert_to_relative_path(self, path, base_path='/public'):
        base_path = get_base_path()
        if path.startswith(base_path):
            relative_path = path[len(base_path):].replace('\\', '/')
            # ç§»é™¤å¼€å¤´çš„ /public å‰ç¼€ï¼ˆå› ä¸º Vite ä¼šè‡ªåŠ¨å°† public æ–‡ä»¶å¤¹æ˜ å°„åˆ°æ ¹è·¯å¾„ï¼‰
            if relative_path.startswith('/public/'):
                relative_path = relative_path[7:]  # ç§»é™¤ '/public'
            return relative_path
        else:
            return path.replace('\\', '/')


class ShowTagsJson(Command):
    description = "Shows the tags and their corresponding markdown files in JSON format."

    def execute(self):
        base_path = get_base_path()
        posts_path = get_posts_path()
        if not os.path.exists(posts_path):
            raise FileNotFoundError(
                f"No such file or directory: '{posts_path}'")

        tags_dict = {}

        # List Markdown files in the root directory
        markdowns_path = os.path.join(posts_path, 'Markdowns')
        if os.path.exists(markdowns_path):
            root_files = [file for file in os.listdir(
                markdowns_path) if file.endswith('.md')]
            for file in root_files:
                file_path = os.path.join(markdowns_path, file)
                metadata = parse_markdown_metadata(file_path)

                # Update tags_dict with tags from metadata
                if 'tags' in metadata and metadata['tags']:
                    tags = metadata['tags']
                    if tags is None:
                        continue
                    if isinstance(tags, str):
                        tags = [tags]
                    for tag in tags:
                        if tag not in tags_dict:
                            tags_dict[tag] = []
                        tags_dict[tag].append(
                            self._convert_to_relative_path(file_path, base_path))

        # List collections and their posts
        directories = [
            file for file in os.listdir(posts_path)
            if os.path.isdir(os.path.join(posts_path, file)) and file not in ['Markdowns', 'Images']
        ]

        for dir_name in directories:
            dir_path = os.path.join(posts_path, dir_name)
            md_files = [file for file in os.listdir(
                dir_path) if file.endswith('.md')]
            for md_file in md_files:
                md_file_path = os.path.join(dir_path, md_file)
                metadata = parse_markdown_metadata(md_file_path)

                # Update tags_dict with tags from metadata
                if 'tags' in metadata and metadata['tags']:
                    tags = metadata['tags']
                    if tags is None:
                        continue
                    if isinstance(tags, str):
                        tags = [tags]
                    for tag in tags:
                        if tag not in tags_dict:
                            tags_dict[tag] = []
                        tags_dict[tag].append(
                            self._convert_to_relative_path(md_file_path, base_path))

        return tags_dict

    def _convert_to_relative_path(self, path, base_path='/public'):
        base_path = get_base_path()
        if path.startswith(base_path):
            relative_path = path[len(base_path):].replace('\\', '/')
            # ç§»é™¤å¼€å¤´çš„ /public å‰ç¼€ï¼ˆå› ä¸º Vite ä¼šè‡ªåŠ¨å°† public æ–‡ä»¶å¤¹æ˜ å°„åˆ°æ ¹è·¯å¾„ï¼‰
            if relative_path.startswith('/public/'):
                relative_path = relative_path[7:]  # ç§»é™¤ '/public'
            return relative_path
        else:
            return path.replace('\\', '/')


class ShowCategoriesJson(Command):
    description = "Shows the categories and their corresponding markdown files in JSON format."

    def execute(self):
        base_path = get_base_path()
        posts_path = get_posts_path()
        if not os.path.exists(posts_path):
            raise FileNotFoundError(
                f"No such file or directory: '{posts_path}'")

        categories_dict = {}

        # List Markdown files in the root directory
        markdowns_path = os.path.join(posts_path, 'Markdowns')
        if os.path.exists(markdowns_path):
            root_files = [os.path.join(markdowns_path, file) for file in os.listdir(
                markdowns_path) if file.endswith('.md')]
            for file_path in root_files:
                self._process_markdown_file(file_path, categories_dict)

        # List collections and their posts
        directories = [
            file for file in os.listdir(posts_path)
            if os.path.isdir(os.path.join(posts_path, file)) and file not in ['Markdowns', 'Images']
        ]

        for dir_name in directories:
            dir_path = os.path.join(posts_path, dir_name)
            md_files = [os.path.join(dir_path, file) for file in os.listdir(
                dir_path) if file.endswith('.md')]
            for md_file_path in md_files:
                self._process_markdown_file(md_file_path, categories_dict)

        return categories_dict

    def _process_markdown_file(self, file_path, categories_dict):
        metadata = parse_markdown_metadata(file_path)
        categories = metadata.get('categories', [])

        if not categories:
            return

        parent_category = categories_dict
        before_category = None
        for category in categories:
            if category not in parent_category:
                parent_category[category] = {
                    'files': [],
                    'childCategories': {}
                }
            before_category = parent_category[category]
            parent_category = parent_category[category]['childCategories']

        # Add the file to the last category in the list
        relative_path = self._convert_to_relative_path(file_path)
        if 'files' not in before_category:
            before_category['files'] = []
        before_category['files'].append(relative_path)

    def _convert_to_relative_path(self, path, base_path='/public'):
        base_path = get_base_path()
        if path.startswith(base_path):
            relative_path = path[len(base_path):].replace('\\', '/')
            # ç§»é™¤å¼€å¤´çš„ /public å‰ç¼€ï¼ˆå› ä¸º Vite ä¼šè‡ªåŠ¨å°† public æ–‡ä»¶å¤¹æ˜ å°„åˆ°æ ¹è·¯å¾„ï¼‰
            if relative_path.startswith('/public/'):
                relative_path = relative_path[7:]  # ç§»é™¤ '/public'
            return relative_path
        else:
            return path.replace('\\', '/')


class ListCollections(Command):
    description = "Lists all collections in the posts directory."

    def execute(self):
        posts_path = get_posts_path()
        if not os.path.exists(posts_path):
            raise FileNotFoundError(
                f"No such file or directory: '{posts_path}'")

        collections = []
        directories = [
            file for file in os.listdir(posts_path)
            if os.path.isdir(os.path.join(posts_path, file))
        ]

        for dir_name in directories:
            dir_path = os.path.join(posts_path, dir_name)
            if dir_name not in ['Markdowns', 'Images']:
                stats = os.stat(dir_path)
                creation_date = datetime.fromtimestamp(
                    stats.st_ctime).strftime('%Y-%m-%d')
                article_count = len(
                    [file for file in os.listdir(dir_path) if file.endswith('.md')])
                collections.append({
                    'name': dir_name,
                    'creation_date': creation_date,
                    'article_count': article_count
                })

        # Format the output for human reading
        formatted_output = []
        for collection in collections:
            formatted_output.append(
                f"Collection: {collection['name']} | Articles: {collection['article_count']} | Created on: {collection['creation_date']}"
            )
        return "\n".join(formatted_output)


class Generate(Command):
    description = "Outputs the posts directory structure, tags, and categories to JSON files."

    def _get_crypto_tag(self):
        """ä» config.js ä¸­è¯»å– CryptoTag é…ç½®"""
        try:
            base_path = get_base_path()
            config_path = os.path.join(base_path, 'src', 'config.js')
            if not os.path.exists(config_path):
                return None

            with open(config_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # åŒ¹é… CryptoTag é…ç½®
            pattern = r"CryptoTag:\s*['\"]([^'\"]*)['\"]"
            match = re.search(pattern, content)
            if match:
                return match.group(1)
            return None
        except:
            return None

    def _collect_crypto_posts(self, crypto_tag):
        """æ”¶é›†åŒ…å«åŠ å¯†æ ‡ç­¾çš„æ–‡ç« """
        if not crypto_tag:
            return []

        posts_path = get_posts_path()
        crypto_posts = []

        # æ£€æŸ¥ Markdowns ç›®å½•
        markdowns_path = os.path.join(posts_path, 'Markdowns')
        if os.path.exists(markdowns_path):
            for file in os.listdir(markdowns_path):
                if file.endswith('.md'):
                    file_path = os.path.join(markdowns_path, file)
                    metadata = parse_markdown_metadata(file_path)
                    tags = metadata.get('tags', [])
                    # ç¡®ä¿ tags æ˜¯åˆ—è¡¨ä¸”ä¸ä¸º None
                    if tags is None:
                        tags = []
                    elif isinstance(tags, str):
                        tags = [tags]

                    if crypto_tag in tags:
                        relative_path = self._convert_to_relative_path(
                            file_path)
                        crypto_posts.append(relative_path)

        # æ£€æŸ¥å„ä¸ªåˆé›†ç›®å½•
        directories = [
            file for file in os.listdir(posts_path)
            if os.path.isdir(os.path.join(posts_path, file)) and file not in ['Markdowns', 'Images']
        ]

        for dir_name in directories:
            dir_path = os.path.join(posts_path, dir_name)
            for file in os.listdir(dir_path):
                if file.endswith('.md'):
                    file_path = os.path.join(dir_path, file)
                    metadata = parse_markdown_metadata(file_path)
                    tags = metadata.get('tags', [])
                    # ç¡®ä¿ tags æ˜¯åˆ—è¡¨ä¸”ä¸ä¸º None
                    if tags is None:
                        tags = []
                    elif isinstance(tags, str):
                        tags = [tags]

                    if crypto_tag in tags:
                        relative_path = self._convert_to_relative_path(
                            file_path)
                        crypto_posts.append(relative_path)

        return crypto_posts

    def _convert_to_relative_path(self, path):
        """è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„"""
        base_path = get_base_path()
        if path.startswith(base_path):
            relative_path = path[len(base_path):].replace('\\', '/')
            # ç§»é™¤å¼€å¤´çš„ /public å‰ç¼€
            if relative_path.startswith('/public/'):
                relative_path = relative_path[7:]
            return relative_path
        else:
            return path.replace('\\', '/')

    def _cleanup_unused_images(self):
        """æ¸…ç†æœªä½¿ç”¨çš„å›¾ç‰‡æ–‡ä»¶ï¼ˆä¼˜åŒ–ç‰ˆï¼šåªæ‰«ææœ‰å›¾ç‰‡ç›®å½•çš„æ–‡ç« ï¼‰"""
        posts_path = get_posts_path()
        images_path = os.path.join(posts_path, 'Images')
        
        if not os.path.exists(images_path):
            return "[å›¾ç‰‡æ¸…ç†] Images ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡æ¸…ç†"
        
        # è·å– Images ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ç« æ–‡ä»¶å¤¹
        article_folders = [
            d for d in os.listdir(images_path)
            if os.path.isdir(os.path.join(images_path, d))
        ]
        
        if not article_folders:
            return "[å›¾ç‰‡æ¸…ç†] Images ç›®å½•ä¸ºç©ºï¼Œæ— éœ€æ¸…ç†"
        
        print(f"[å›¾ç‰‡æ¸…ç†] å‘ç° {len(article_folders)} ä¸ªæ–‡ç« å›¾ç‰‡ç›®å½•")
        
        deleted_count = 0
        total_checked = 0
        not_found_articles = []
        
        # åªæ‰«ææœ‰å›¾ç‰‡ç›®å½•çš„æ–‡ç« 
        for article_name in article_folders:
            article_image_dir = os.path.join(images_path, article_name)
            
            # æŸ¥æ‰¾å¯¹åº”çš„ markdown æ–‡ä»¶
            md_file_path = self._find_markdown_file(posts_path, article_name)
            
            if not md_file_path:
                print(f"[å›¾ç‰‡æ¸…ç†] è­¦å‘Š: æœªæ‰¾åˆ°æ–‡ç«  '{article_name}.md'ï¼Œä¿ç•™å…¶å›¾ç‰‡ç›®å½•")
                not_found_articles.append(article_name)
                continue
            
            # æå–æ–‡ç« ä¸­ä½¿ç”¨çš„å›¾ç‰‡
            used_images = self._extract_images_from_markdown(md_file_path)
            
            # è·å–è¯¥ç›®å½•ä¸‹çš„æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
            existing_images = []
            for file in os.listdir(article_image_dir):
                file_path = os.path.join(article_image_dir, file)
                if os.path.isfile(file_path):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾ç‰‡æ–‡ä»¶
                    ext = os.path.splitext(file)[1].lower()
                    if ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp', '.svg', '.ico', '.bmp']:
                        existing_images.append(file)
            
            total_checked += len(existing_images)
            
            # æ‰¾å‡ºæœªä½¿ç”¨çš„å›¾ç‰‡
            for image_file in existing_images:
                # æ£€æŸ¥è¿™ä¸ªå›¾ç‰‡æ˜¯å¦åœ¨ä½¿ç”¨åˆ—è¡¨ä¸­
                is_used = False
                for used_image in used_images:
                    # åŒ¹é…æ–‡ä»¶åï¼ˆå¿½ç•¥è·¯å¾„ï¼‰
                    if image_file in used_image or used_image.endswith(image_file):
                        is_used = True
                        break
                
                if not is_used:
                    # åˆ é™¤æœªä½¿ç”¨çš„å›¾ç‰‡
                    image_path = os.path.join(article_image_dir, image_file)
                    try:
                        os.remove(image_path)
                        print(f"[å›¾ç‰‡æ¸…ç†] âœ“ åˆ é™¤: {article_name}/{image_file}")
                        deleted_count += 1
                    except Exception as e:
                        print(f"[å›¾ç‰‡æ¸…ç†] âœ— åˆ é™¤å¤±è´¥ {article_name}/{image_file}: {e}")
            
            # å¦‚æœç›®å½•ä¸ºç©ºï¼Œåˆ é™¤ç›®å½•
            try:
                if not os.listdir(article_image_dir):
                    os.rmdir(article_image_dir)
                    print(f"[å›¾ç‰‡æ¸…ç†] âœ“ åˆ é™¤ç©ºç›®å½•: {article_name}/")
            except:
                pass
        
        result_lines = [
            f"[å›¾ç‰‡æ¸…ç†] å®Œæˆï¼",
            f"  - æ‰«æäº† {len(article_folders)} ä¸ªæ–‡ç« å›¾ç‰‡ç›®å½•",
            f"  - æ£€æŸ¥äº† {total_checked} å¼ å›¾ç‰‡",
            f"  - åˆ é™¤äº† {deleted_count} å¼ æœªä½¿ç”¨çš„å›¾ç‰‡"
        ]
        
        if not_found_articles:
            result_lines.append(f"  - {len(not_found_articles)} ä¸ªæ–‡ç« æœªæ‰¾åˆ°å¯¹åº” .md æ–‡ä»¶ï¼ˆå·²ä¿ç•™å›¾ç‰‡ï¼‰")
        
        return '\n'.join(result_lines)
    
    def _find_markdown_file(self, posts_path, article_name):
        """æŸ¥æ‰¾æ–‡ç« çš„ markdown æ–‡ä»¶è·¯å¾„"""
        # å…ˆåœ¨ Markdowns ç›®å½•æŸ¥æ‰¾
        markdowns_path = os.path.join(posts_path, 'Markdowns', f"{article_name}.md")
        if os.path.exists(markdowns_path):
            return markdowns_path
        
        # åœ¨å„ä¸ªåˆé›†ç›®å½•ä¸­æŸ¥æ‰¾
        directories = [
            d for d in os.listdir(posts_path)
            if os.path.isdir(os.path.join(posts_path, d)) and d not in ['Markdowns', 'Images']
        ]
        
        for dir_name in directories:
            file_path = os.path.join(posts_path, dir_name, f"{article_name}.md")
            if os.path.exists(file_path):
                return file_path
        
        return None
    
    def _extract_images_from_markdown(self, file_path):
        """ä» Markdown æ–‡ä»¶ä¸­æå–æ‰€æœ‰å›¾ç‰‡å¼•ç”¨ï¼ˆåŒ…æ‹¬ metadata ä¸­çš„ img å­—æ®µï¼‰"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            images = []
            
            # 1. è§£æ metadata ä¸­çš„ img å­—æ®µ
            metadata = parse_markdown_metadata(file_path)
            if 'img' in metadata and metadata['img']:
                img_value = metadata['img']
                # img å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨
                if isinstance(img_value, str):
                    if img_value.strip():  # ç¡®ä¿ä¸æ˜¯ç©ºå­—ç¬¦ä¸²
                        images.append(img_value.strip())
                elif isinstance(img_value, list):
                    images.extend([img.strip() for img in img_value if img.strip()])
            
            # 2. åŒ¹é… Markdown å›¾ç‰‡è¯­æ³•: ![alt](path)
            # æ”¯æŒå¤šç§æ ¼å¼ï¼š
            # - ![](image.png)
            # - ![alt](./image.png)
            # - ![alt](../folder/image.png)
            # - ![alt](/Posts/Images/article/image.png)
            # - ![alt](article/image.png)
            
            image_pattern = r'!\[.*?\]\(([^)]+)\)'
            matches = re.findall(image_pattern, content)
            
            # æå–å›¾ç‰‡è·¯å¾„
            for match in matches:
                # ç§»é™¤å¯èƒ½çš„å¼•å·
                image_path = match.strip().strip('\'"')
                # ç§»é™¤ URL å‚æ•°ï¼ˆå¦‚ ?width=100ï¼‰
                if '?' in image_path:
                    image_path = image_path.split('?')[0]
                images.append(image_path)
            
            return images
        except Exception as e:
            print(f"[å›¾ç‰‡æ¸…ç†] è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return []

    def execute(self):
        posts_path = get_posts_path()
        assets_path = get_assets_path()
        
        # æ£€æŸ¥å¹¶åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„
        if not os.path.exists(posts_path):
            print("[Generate] æ£€æµ‹åˆ° Posts ç›®å½•ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...")
            os.makedirs(posts_path, exist_ok=True)
            
            # åˆ›å»ºåŸºæœ¬ç›®å½•ç»“æ„
            markdowns_path = os.path.join(posts_path, 'Markdowns')
            images_path = os.path.join(posts_path, 'Images')
            os.makedirs(markdowns_path, exist_ok=True)
            os.makedirs(images_path, exist_ok=True)
            
            print("[Generate] âœ“ å·²åˆ›å»ºåŸºæœ¬ç›®å½•ç»“æ„")
            print("[Generate] æç¤º: å»ºè®®å…ˆä½¿ç”¨ã€Œåˆå§‹åŒ–åšå®¢æ¡†æ¶ã€åŠŸèƒ½å®Œæ•´åˆå§‹åŒ–é¡¹ç›®")
        
        posts_output_path = os.path.join(assets_path, 'PostDirectory.json')
        tags_output_path = os.path.join(assets_path, 'Tags.json')
        categories_output_path = os.path.join(assets_path, 'Categories.json')
        crypto_output_path = os.path.join(assets_path, 'Crypto.json')

        show_posts_command = ShowPostsJson()
        posts_directory = show_posts_command.execute()

        show_tags_command = ShowTagsJson()
        tags_dictionary = show_tags_command.execute()

        show_categories_command = ShowCategoriesJson()
        categories_dictionary = show_categories_command.execute()

        # æ”¶é›†åŠ å¯†æ–‡ç« 
        crypto_tag = self._get_crypto_tag()
        crypto_posts = self._collect_crypto_posts(crypto_tag)

        # æ¸…ç†æœªä½¿ç”¨çš„å›¾ç‰‡
        print("[Generate] å¼€å§‹æ¸…ç†æœªä½¿ç”¨çš„å›¾ç‰‡...")
        cleanup_result = self._cleanup_unused_images()
        print(cleanup_result)

        # Ensure the output directory exists
        os.makedirs(os.path.dirname(posts_output_path), exist_ok=True)
        os.makedirs(os.path.dirname(tags_output_path), exist_ok=True)
        os.makedirs(os.path.dirname(categories_output_path), exist_ok=True)
        os.makedirs(os.path.dirname(crypto_output_path), exist_ok=True)

        # Output posts directory to JSON file
        with open(posts_output_path, 'w', encoding='utf-8') as json_file:
            json.dump(posts_directory, json_file, indent=2, ensure_ascii=False)

        # Output tags dictionary to JSON file
        with open(tags_output_path, 'w', encoding='utf-8') as json_file:
            json.dump(tags_dictionary, json_file, indent=2, ensure_ascii=False)

        # Output categories dictionary to JSON file
        with open(categories_output_path, 'w', encoding='utf-8') as json_file:
            json.dump(categories_dictionary, json_file,
                      indent=2, ensure_ascii=False)

        # Output crypto posts to JSON file with password preservation
        existing_password = ""
        if os.path.exists(crypto_output_path):
            try:
                with open(crypto_output_path, 'r', encoding='utf-8') as json_file:
                    existing_data = json.load(json_file)
                    # å¦‚æœç°æœ‰æ–‡ä»¶åŒ…å« password å­—æ®µï¼Œä¿ç•™å®ƒ
                    if isinstance(existing_data, dict) and 'password' in existing_data:
                        existing_password = existing_data.get('password', '')
            except:
                pass

        # æ„å»ºæ–°çš„ crypto æ•°æ®ç»“æ„
        crypto_data = {
            'password': existing_password,
            'posts': crypto_posts
        }

        with open(crypto_output_path, 'w', encoding='utf-8') as json_file:
            json.dump(crypto_data, json_file, indent=2, ensure_ascii=False)

        # åŠ å¯†æ–‡ç« 
        encrypted_count = 0
        if crypto_posts and existing_password:
            print(f"[Crypto] å¼€å§‹åŠ å¯† {len(crypto_posts)} ç¯‡æ–‡ç« ...")

            # åˆ›å»º cryptoPosts ç›®å½•ï¼ˆåœ¨é¡¹ç›®æ ¹ç›®å½•ï¼‰
            base_path = get_base_path()
            crypto_posts_dir = os.path.join(base_path, 'cryptoPosts')
            os.makedirs(crypto_posts_dir, exist_ok=True)

            for post_path in crypto_posts:
                # è½¬æ¢ä¸ºå®Œæ•´è·¯å¾„
                full_path = os.path.join(
                    base_path, 'public', post_path.lstrip('/'))

                if os.path.exists(full_path):
                    # ç”ŸæˆåŠ å¯†åçš„æ–‡ä»¶è·¯å¾„ï¼ˆä¿æŒç›¸åŒçš„ç›®å½•ç»“æ„ï¼‰
                    relative_path = os.path.relpath(
                        full_path, os.path.join(base_path, 'public', 'Posts'))
                    encrypted_path = os.path.join(
                        crypto_posts_dir, relative_path)

                    # åŠ å¯†æ–‡ä»¶
                    result = CryptoEncryptor.encrypt_file(
                        full_path, existing_password, encrypted_path)
                    if result['success']:
                        encrypted_count += 1
                        print(f"[Crypto] âœ“ {os.path.basename(full_path)}")
                    else:
                        print(f"[Crypto] âœ— {result['message']}")
                else:
                    print(f"[Crypto] è­¦å‘Š: æ–‡ä»¶ä¸å­˜åœ¨ {full_path}")

            print(f"[Crypto] åŠ å¯†å®Œæˆ: {encrypted_count}/{len(crypto_posts)} ç¯‡æ–‡ç« ")

        return f"Post directory output to {posts_output_path}\nTags output to {tags_output_path}\nCategories output to {categories_output_path}\nCrypto posts output to {crypto_output_path} ({len(crypto_posts)} posts)\nEncrypted: {encrypted_count} files\n{cleanup_result}"


class AddPost(Command):
    description = "Adds a new post with the given name and optional collection."

    def execute(self):
        posts_path = get_posts_path()
        output_path = os.path.join(get_assets_path(), 'PostDirectory.json')
        name = input("Enter the name of the new post: ").strip()
        collection = input(
            "Enter the collection name (optional): ").strip() or None

        if not name:
            return "Error: No post name provided."

        # Determine the directory based on whether a collection is provided
        directory = os.path.join(
            posts_path, 'Markdowns') if not collection else os.path.join(posts_path, collection)
        os.makedirs(directory, exist_ok=True)

        # Generate the file path and metadata
        file_path = os.path.join(directory, f"{name}.md")
        date_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        metadata = f"""---
title: {name}
date: {date_str}
tags: 
categories: 
pre: 
img: 
---
"""

        # Check if the file already exists
        if os.path.exists(file_path):
            overwrite = input(
                f"File '{file_path}' already exists. Overwrite? (Y/N): ").strip().lower()
            if overwrite not in ['y', 'yes']:
                return f"Post '{name}' creation aborted."

        # Write the metadata to the file
        with open(file_path, 'w', encoding='utf-8') as file:
            file.write(metadata)

        # Output the posts directory structure to a JSON file
        output_command = Generate()
        output_result = output_command.execute()

        return f"Post '{name}' created at {file_path}\n{output_result}"


class DeletePost(Command):
    description = "Deletes a post with the given name from the optional collection."

    def execute(self):
        posts_path = get_posts_path()
        output_path = os.path.join(get_assets_path(), 'PostDirectory.json')
        name = input("Enter the name of the post to delete: ").strip()
        collection = input(
            "Enter the collection name (optional): ").strip() or None

        if not name:
            return "Error: No post name provided."

        # Determine the directory based on whether a collection is provided
        directory = os.path.join(
            posts_path, 'Markdowns') if not collection else os.path.join(posts_path, collection)
        file_path = os.path.join(directory, f"{name}.md")

        # Check if the file exists
        if not os.path.exists(file_path):
            return f"Error: Post '{name}' does not exist."

        # Get file metadata
        stats = os.stat(file_path)
        creation_date = datetime.fromtimestamp(
            stats.st_ctime).strftime('%Y-%m-%d %H:%M:%S')
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.read()
            content_length = len(content)

        # Ask for confirmation
        print(
            f"Post '{name}' was created on {creation_date} and has {content_length} characters.")
        confirm = input(
            f"Are you sure you want to delete this post? (Y/N): ").strip().lower()
        if confirm not in ['y', 'yes']:
            return f"Deletion of post '{name}' aborted."

        # Delete the file
        os.remove(file_path)

        # Output the posts directory structure to a JSON file
        output_command = Generate()
        output_result = output_command.execute()

        return f"Post '{name}' deleted.\n{output_result}"


class DeleteCollection(Command):
    description = "Deletes a collection and all its posts."

    def execute(self):
        posts_path = get_posts_path()
        output_path = os.path.join(get_assets_path(), 'PostDirectory.json')
        collection = input(
            "Enter the name of the collection to delete: ").strip()

        if not collection:
            return "Error: No collection name provided."

        directory = os.path.join(posts_path, collection)

        # Check if the directory exists
        if not os.path.exists(directory) or not os.path.isdir(directory):
            return f"Error: Collection '{collection}' does not exist."

        # List the posts in the collection
        posts = [file for file in os.listdir(
            directory) if file.endswith('.md')]

        if posts:
            print(f"Collection '{collection}' contains the following posts:")
            for post in posts:
                print(f" - {post}")
        else:
            print(f"Collection '{collection}' is empty.")

        # Ask for confirmation
        confirm = input(
            f"Are you sure you want to delete this collection? (Posts will be moved to Markdowns) (Y/N): ").strip().lower()
        if confirm not in ['y', 'yes']:
            return f"Deletion of collection '{collection}' aborted."

        # Move all .md files to Markdowns directory
        markdowns_path = os.path.join(posts_path, 'Markdowns')
        os.makedirs(markdowns_path, exist_ok=True)

        moved_count = 0
        for post in posts:
            src_path = os.path.join(directory, post)
            dst_path = os.path.join(markdowns_path, post)

            # Handle filename conflicts
            counter = 1
            base_name, ext = os.path.splitext(post)
            while os.path.exists(dst_path):
                dst_path = os.path.join(
                    markdowns_path, f"{base_name}_{counter}{ext}")
                counter += 1

            shutil.move(src_path, dst_path)
            moved_count += 1
            print(f"Moved: {post} -> Markdowns/{os.path.basename(dst_path)}")

        # Delete the entire collection directory and remaining files
        shutil.rmtree(directory)

        # Output the posts directory structure to a JSON file
        output_command = Generate()
        output_result = output_command.execute()

        return f"Collection '{collection}' deleted. {moved_count} posts moved to Markdowns.\n{output_result}"


class ListAllPosts(Command):
    description = "Lists all posts and collections in the posts directory."

    def execute(self):
        base_path = get_base_path()
        posts_path = get_posts_path()
        if not os.path.exists(posts_path):
            raise FileNotFoundError(
                f"No such file or directory: '{posts_path}'")

        formatted_output = []

        # List Markdown files in the root directory
        markdowns_path = os.path.join(posts_path, 'Markdowns')
        if os.path.exists(markdowns_path):
            root_files = [file for file in os.listdir(
                markdowns_path) if file.endswith('.md')]
            for file in root_files:
                file_path = os.path.join(markdowns_path, file)
                stats = os.stat(file_path)
                creation_date = datetime.fromtimestamp(
                    stats.st_ctime).strftime('%Y-%m-%d')
                metadata = parse_markdown_metadata(file_path)
                title = metadata.get('title', 'Untitled')
                content = read_file_safe(file_path)
                content_length = len(content)
                formatted_output.append(
                    f"Post: {file} | Title: {title} | Created on: {creation_date} | Characters: {content_length}")

        # List collections and their posts
        directories = [
            file for file in os.listdir(posts_path)
            if os.path.isdir(os.path.join(posts_path, file)) and file not in ['Markdowns', 'Images']
        ]

        for dir_name in directories:
            dir_path = os.path.join(posts_path, dir_name)
            stats = os.stat(dir_path)
            creation_date = datetime.fromtimestamp(
                stats.st_ctime).strftime('%Y-%m-%d')
            md_files = [file for file in os.listdir(
                dir_path) if file.endswith('.md')]
            formatted_output.append(
                f"Collection: {dir_name} | Created on: {creation_date} | Posts: {len(md_files)}")
            for md_file in md_files:
                md_file_path = os.path.join(dir_path, md_file)
                md_stats = os.stat(md_file_path)
                md_creation_date = datetime.fromtimestamp(
                    md_stats.st_ctime).strftime('%Y-%m-%d')
                metadata = parse_markdown_metadata(md_file_path)
                title = metadata.get('title', 'Untitled')
                content = read_file_safe(md_file_path)
                content_length = len(content)
                formatted_output.append(
                    f"    Post: {md_file} | Title: {title} | Created on: {md_creation_date} | Characters: {content_length}")

        return "\n".join(formatted_output)


class Build(Command):
    description = "Builds the blog project using npm run build."

    def execute(self):
        base_path = get_base_path()
        crypto_json_path = os.path.join(
            base_path, 'public', 'assets', 'Crypto.json')
        temp_crypto_json_path = os.path.join(base_path, 'Crypto.json')
        crypto_posts_dir = os.path.join(base_path, 'cryptoPosts')
        posts_dir = os.path.join(base_path, 'public', 'Posts')
        backup_dir = os.path.join(base_path, 'Posts_backup_temp')

        crypto_moved = False
        swapped_files = []  # è®°å½•äº¤æ¢çš„æ–‡ä»¶ä¿¡æ¯

        try:
            # Build å‰ï¼šå°† Crypto.json æš‚æ—¶ç§»å‡º public ç›®å½•ï¼Œé¿å…å¯†ç æ˜æ–‡è¢« push
            if os.path.exists(crypto_json_path):
                shutil.move(crypto_json_path, temp_crypto_json_path)
                crypto_moved = True
                print("[Security] Crypto.json å·²æš‚æ—¶ç§»å‡º public ç›®å½•")

            # Build å‰ï¼šåªäº¤æ¢éœ€è¦åŠ å¯†çš„æ–‡ä»¶
            if os.path.exists(crypto_posts_dir):
                print("[Crypto] å¼€å§‹äº¤æ¢åŠ å¯†æ–‡ä»¶...")
                os.makedirs(backup_dir, exist_ok=True)

                # éå† cryptoPosts ä¸­çš„æ‰€æœ‰åŠ å¯†æ–‡ä»¶
                for root, dirs, files in os.walk(crypto_posts_dir):
                    for file in files:
                        if file.endswith('.md'):
                            # åŠ å¯†æ–‡ä»¶è·¯å¾„
                            encrypted_file = os.path.join(root, file)
                            # ç›¸å¯¹è·¯å¾„
                            rel_path = os.path.relpath(
                                encrypted_file, crypto_posts_dir)
                            # public/Posts ä¸­å¯¹åº”çš„æ˜æ–‡æ–‡ä»¶
                            original_file = os.path.join(posts_dir, rel_path)
                            # å¤‡ä»½ä½ç½®
                            backup_file = os.path.join(backup_dir, rel_path)

                            if os.path.exists(original_file):
                                # ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
                                os.makedirs(os.path.dirname(
                                    backup_file), exist_ok=True)

                                # æ­¥éª¤1ï¼šå°†æ˜æ–‡æ–‡ä»¶ç§»åŠ¨åˆ°å¤‡ä»½ä½ç½®
                                shutil.move(original_file, backup_file)

                                # æ­¥éª¤2ï¼šå°†å¯†æ–‡æ–‡ä»¶å¤åˆ¶åˆ° public/Posts
                                shutil.copy2(encrypted_file, original_file)

                                # è®°å½•äº¤æ¢ä¿¡æ¯
                                swapped_files.append({
                                    'original_file': original_file,
                                    'backup_file': backup_file,
                                    'encrypted_file': encrypted_file
                                })
                                print(f"[Crypto] äº¤æ¢: {rel_path}")

                print(f"[Crypto] å·²äº¤æ¢ {len(swapped_files)} ä¸ªåŠ å¯†æ–‡ä»¶")

            # åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œ npm run build
            # Windows éœ€è¦ shell=True æˆ–ä½¿ç”¨ npm.cmd
            result = subprocess.run(
                'npm run build',
                cwd=base_path,
                capture_output=True,
                text=True,
                shell=True,  # åœ¨ Windows ä¸Šéœ€è¦ shell=True
                encoding='utf-8',  # æŒ‡å®š UTF-8 ç¼–ç é¿å… GBK è§£ç é”™è¯¯
                errors='replace',  # é‡åˆ°æ— æ³•è§£ç çš„å­—ç¬¦æ—¶æ›¿æ¢è€Œä¸æ˜¯æŠ¥é”™
                check=True
            )

            # Build å®Œæˆåï¼šå°†åŠ å¯†æ–‡ä»¶å¤åˆ¶åˆ° dist/Posts
            # è¿™æ˜¯å¿…éœ€çš„ï¼Œå› ä¸º vite åœ¨ build æ—¶å¯èƒ½å·²ç»ç¼“å­˜äº† public ç›®å½•
            if swapped_files:
                print("[Crypto] å°†åŠ å¯†æ–‡ä»¶å¤åˆ¶åˆ° dist ç›®å½•...")
                dist_posts_dir = os.path.join(base_path, 'dist', 'Posts')

                for swap_info in swapped_files:
                    try:
                        # è®¡ç®—ç›¸å¯¹è·¯å¾„
                        rel_path = os.path.relpath(
                            swap_info['encrypted_file'], crypto_posts_dir)
                        # dist ä¸­çš„ç›®æ ‡æ–‡ä»¶
                        dist_file = os.path.join(dist_posts_dir, rel_path)

                        # ç¡®ä¿ç›®å½•å­˜åœ¨
                        os.makedirs(os.path.dirname(dist_file), exist_ok=True)

                        # å¤åˆ¶åŠ å¯†æ–‡ä»¶åˆ° dist
                        shutil.copy2(swap_info['encrypted_file'], dist_file)
                        print(f"[Crypto] å¤åˆ¶åˆ° dist: {rel_path}")
                    except Exception as e:
                        print(f"[Crypto] å¤åˆ¶å¤±è´¥ {rel_path}: {e}")

                print(f"[Crypto] å·²å°† {len(swapped_files)} ä¸ªåŠ å¯†æ–‡ä»¶å¤åˆ¶åˆ° dist")

            return f"Build successful!\n{result.stdout}"

        except subprocess.CalledProcessError as e:
            raise Exception(f"Build failed:\n{e.stderr}")
        except FileNotFoundError:
            raise Exception(
                "npm not found. Please ensure Node.js is installed and added to PATH.")
        finally:
            # Build åï¼šæ¢å¤ Crypto.json åˆ°åŸä½ç½®
            if crypto_moved and os.path.exists(temp_crypto_json_path):
                shutil.move(temp_crypto_json_path, crypto_json_path)
                print("[Security] Crypto.json å·²æ¢å¤åˆ° public/assets ç›®å½•")

            # Build åï¼šæ¢å¤è¢«äº¤æ¢çš„æ–‡ä»¶
            if swapped_files:
                print("[Crypto] å¼€å§‹æ¢å¤åŸå§‹æ–‡ä»¶...")
                for swap_info in swapped_files:
                    try:
                        # åˆ é™¤ public/Posts ä¸­çš„å¯†æ–‡
                        if os.path.exists(swap_info['original_file']):
                            os.remove(swap_info['original_file'])

                        # å°†æ˜æ–‡ä»å¤‡ä»½ä½ç½®ç§»å›
                        if os.path.exists(swap_info['backup_file']):
                            shutil.move(
                                swap_info['backup_file'], swap_info['original_file'])
                            print(
                                f"[Crypto] æ¢å¤: {os.path.basename(swap_info['original_file'])}")
                    except Exception as e:
                        print(
                            f"[Crypto] æ¢å¤å¤±è´¥ {os.path.basename(swap_info['original_file'])}: {e}")

                print(f"[Crypto] å·²æ¢å¤ {len(swapped_files)} ä¸ªæ–‡ä»¶")

                # æ¸…ç†å¤‡ä»½ç›®å½•
                if os.path.exists(backup_dir):
                    try:
                        shutil.rmtree(backup_dir)
                        print("[Crypto] å·²æ¸…ç†ä¸´æ—¶å¤‡ä»½ç›®å½•")
                    except:
                        pass


class GetConfig(Command):
    description = "Gets the current blog configuration from config.js."

    def execute(self):
        base_path = get_base_path()
        config_path = os.path.join(base_path, 'src', 'config.js')

        if not os.path.exists(config_path):
            raise FileNotFoundError(f"Config file not found: {config_path}")

        with open(config_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # è§£æé…ç½®æ–‡ä»¶
        config = {}

        # åŒ¹é…å­—ç¬¦ä¸²å€¼ï¼ˆå•å¼•å·æˆ–åŒå¼•å·ï¼‰- æ³¨æ„ CryptoTag ä¹Ÿä¼šè¢«è¿™é‡ŒåŒ¹é…
        string_pattern = r"(\w+):\s*['\"]([^'\"]*)['\"]"
        for match in re.finditer(string_pattern, content):
            key = match.group(1)
            value = match.group(2)
            config[key] = value

        # åŒ¹é…æ•°å­—å€¼ï¼ˆåŒ…æ‹¬å°æ•°ï¼‰
        number_pattern = r"(\w+):\s*(\d+\.?\d*)\s*[,\/]"
        for match in re.finditer(number_pattern, content):
            key = match.group(1)
            value = match.group(2)
            if key not in config:  # é¿å…è¦†ç›–å·²åŒ¹é…çš„å­—ç¬¦ä¸²
                config[key] = float(value) if '.' in value else int(value)

        # åŒ¹é…å¸ƒå°”å€¼
        bool_pattern = r"(\w+):\s*(true|false)\s*[,\/]"
        for match in re.finditer(bool_pattern, content):
            key = match.group(1)
            config[key] = match.group(2) == 'true'

        # åŒ¹é…ç®€å•å­—ç¬¦ä¸²æ•°ç»„ï¼ˆå¦‚ InfoListUpï¼‰
        list_pattern = r"(\w+List(?:Up|Down|Float)?):\s*\[([^\]]+)\]"
        for match in re.finditer(list_pattern, content):
            key = match.group(1)
            array_content = match.group(2)
            # æå–æ•°ç»„ä¸­çš„å­—ç¬¦ä¸²
            items = re.findall(r"['\"]([^'\"]+)['\"]", array_content)
            config[key] = items

        # åŒ¹é… Links æ•°ç»„ï¼ˆå¯¹è±¡æ•°ç»„ï¼‰
        links_pattern = r"Links:\s*\[(.*?)\]"
        links_match = re.search(links_pattern, content, re.DOTALL)
        if links_match:
            links_content = links_match.group(1)
            links = []
            # åŒ¹é…æ¯ä¸ªé“¾æ¥å¯¹è±¡ï¼ˆæ”¯æŒå°¾éšé€—å·ï¼‰
            link_objects = re.finditer(
                r"\{\s*name:\s*['\"]([^'\"]+)['\"]\s*,\s*url:\s*['\"]([^'\"]+)['\"]\s*,?\s*\}", links_content, re.DOTALL)
            for link_obj in link_objects:
                links.append({
                    'name': link_obj.group(1),
                    'url': link_obj.group(2)
                })
            config['Links'] = links

        return json.dumps(config, indent=2, ensure_ascii=False)


class UpdateConfig(Command):
    description = "Updates the blog configuration in config.js."

    def execute(self, **kwargs):
        base_path = get_base_path()
        config_path = os.path.join(base_path, 'src', 'config.js')

        if not os.path.exists(config_path):
            raise FileNotFoundError(f"Config file not found: {config_path}")

        with open(config_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # æ›´æ–°é…ç½®é¡¹
        for key, value in kwargs.items():
            # æ ¹æ®å€¼ç±»å‹å†³å®šå¦‚ä½•æ ¼å¼åŒ–
            if isinstance(value, list):
                # å¤„ç†æ•°ç»„ç±»å‹
                if key == 'Links':
                    # Links æ˜¯å¯¹è±¡æ•°ç»„
                    links_str = '[\n'
                    for link in value:
                        links_str += f"        {{\n            name: '{link['name']}',\n            url: '{link['url']}',\n        }},\n"
                    links_str += '    ]'
                    pattern = rf"{key}:\s*\[[^\]]*\]"
                    content = re.sub(
                        pattern, f"{key}: {links_str}", content, flags=re.DOTALL)
                else:
                    # å…¶ä»– List æ˜¯å­—ç¬¦ä¸²æ•°ç»„
                    if value:
                        items_str = ',\n        '.join(
                            [f"'{item}'" for item in value])
                        formatted_value = f"[\n        {items_str},\n    ]"
                    else:
                        formatted_value = "[\n    ]"
                    pattern = rf"{key}:\s*\[[^\]]*\]"
                    content = re.sub(
                        pattern, f"{key}: {formatted_value}", content, flags=re.DOTALL)
            elif isinstance(value, str):
                formatted_value = f"'{value}'"
                pattern = rf"\b{key}\s*:\s*[^,\n]+([,\/])"
                replacement = f"{key}: {formatted_value}\\1"
                content = re.sub(pattern, replacement, content)
            elif isinstance(value, bool):
                formatted_value = 'true' if value else 'false'
                pattern = rf"\b{key}\s*:\s*[^,\n]+([,\/])"
                replacement = f"{key}: {formatted_value}\\1"
                content = re.sub(pattern, replacement, content)
            else:
                formatted_value = str(value)
                pattern = rf"\b{key}\s*:\s*[^,\n]+([,\/])"
                replacement = f"{key}: {formatted_value}\\1"
                content = re.sub(pattern, replacement, content)

        # å†™å›æ–‡ä»¶
        with open(config_path, 'w', encoding='utf-8') as f:
            f.write(content)

        return f"Configuration updated successfully!"


class UpdateCryptoPassword(Command):
    description = "Updates the password in Crypto.json file."

    def execute(self, password):
        base_path = get_base_path()
        assets_path = get_assets_path()
        crypto_output_path = os.path.join(assets_path, 'Crypto.json')

        # è¯»å–ç°æœ‰çš„ Crypto.json
        existing_posts = []
        if os.path.exists(crypto_output_path):
            try:
                with open(crypto_output_path, 'r', encoding='utf-8') as json_file:
                    existing_data = json.load(json_file)
                    # å¦‚æœç°æœ‰æ–‡ä»¶åŒ…å« posts å­—æ®µï¼Œä¿ç•™å®ƒ
                    if isinstance(existing_data, dict) and 'posts' in existing_data:
                        existing_posts = existing_data.get('posts', [])
            except:
                pass

        # æ„å»ºæ–°çš„ crypto æ•°æ®ç»“æ„
        crypto_data = {
            'password': password,
            'posts': existing_posts
        }

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(crypto_output_path), exist_ok=True)

        # å†™å…¥æ–‡ä»¶
        with open(crypto_output_path, 'w', encoding='utf-8') as json_file:
            json.dump(crypto_data, json_file, indent=2, ensure_ascii=False)

        return f"Crypto password updated successfully!"


class GetCryptoPassword(Command):
    description = "Gets the password from Crypto.json file."

    def execute(self):
        base_path = get_base_path()
        assets_path = get_assets_path()
        crypto_output_path = os.path.join(assets_path, 'Crypto.json')

        if os.path.exists(crypto_output_path):
            try:
                with open(crypto_output_path, 'r', encoding='utf-8') as json_file:
                    data = json.load(json_file)
                    if isinstance(data, dict):
                        return data.get('password', '')
            except:
                pass
        return ''


class MigrateFromHexo(Command):
    description = "Migrates blog posts from Hexo format to KMBlog format."

    def execute(self):
        """è¿ç§»æ‰€æœ‰ Hexo æ ¼å¼çš„æ–‡ç« åˆ° KMBlog æ ¼å¼"""
        posts_path = get_posts_path()

        if not os.path.exists(posts_path):
            raise FileNotFoundError(f"Posts directory not found: {posts_path}")

        migrated_count = 0
        skipped_count = 0
        error_count = 0

        # ç¬¬ä¸€æ­¥ï¼šè¿ç§»å›¾ç‰‡
        print("[è¿ç§»] å¼€å§‹è¿ç§»å›¾ç‰‡...")
        image_migration_result = self._migrate_images(posts_path)
        print(image_migration_result)

        # ç¬¬äºŒæ­¥ï¼šç§»åŠ¨ md æ–‡ä»¶åˆ°ç¬¬ä¸€å±‚ï¼ˆCollection ç›®å½•æ ¹ï¼‰
        print("[è¿ç§»] å¼€å§‹æ•´ç† markdown æ–‡ä»¶...")
        md_migration_result = self._reorganize_markdown_files(posts_path)
        print(md_migration_result)

        # ç¬¬ä¸‰æ­¥ï¼šé€’å½’æ‰«ææ‰€æœ‰ .md æ–‡ä»¶å¹¶æ›´æ–°æ ¼å¼
        print("[è¿ç§»] å¼€å§‹è¿ç§» markdown æ ¼å¼...")
        for root, dirs, files in os.walk(posts_path):
            for file in files:
                if file.endswith('.md'):
                    file_path = os.path.join(root, file)
                    try:
                        if self._migrate_file(file_path):
                            migrated_count += 1
                        else:
                            skipped_count += 1
                    except Exception as e:
                        print(f"[è¿ç§»é”™è¯¯] {file}: {e}")
                        error_count += 1

        # ç¬¬å››æ­¥ï¼šåˆ é™¤ç©ºçš„ç¬¬äºŒå±‚æ–‡ä»¶å¤¹
        print("[è¿ç§»] å¼€å§‹åˆ é™¤åŸ Hexo æ–‡ä»¶å¤¹...")
        cleanup_result = self._cleanup_empty_directories(posts_path)
        print(cleanup_result)

        return f"è¿ç§»å®Œæˆï¼\n{image_migration_result}\n{md_migration_result}\nMarkdown æ ¼å¼è¿ç§»: {migrated_count} ç¯‡, è·³è¿‡: {skipped_count} ç¯‡, é”™è¯¯: {error_count} ç¯‡\n{cleanup_result}"

    def _migrate_images(self, posts_path: str) -> str:
        """è¿ç§»æ‰€æœ‰å›¾ç‰‡åˆ° Images ç›®å½•ï¼Œå¤„ç†åç§°å†²çª"""
        images_dir = os.path.join(posts_path, 'Images')
        os.makedirs(images_dir, exist_ok=True)

        image_extensions = {'.jpg', '.jpeg',
                            '.png', '.gif', '.webp', '.svg', '.ico'}
        migrated_count = 0
        image_map = {}  # è®°å½•åŸå§‹è·¯å¾„å’Œæ–°æ–‡ä»¶åçš„æ˜ å°„

        # éå†æ‰€æœ‰å­ç›®å½•å¯»æ‰¾å›¾ç‰‡
        for root, dirs, files in os.walk(posts_path):
            # è·³è¿‡ Images ç›®å½•æœ¬èº«
            if root == images_dir:
                continue

            for file in files:
                if os.path.splitext(file)[1].lower() in image_extensions:
                    # è·³è¿‡ /public/Posts ç›´æ¥å­ç›®å½•ä¸‹çš„ image.png æ–‡ä»¶
                    if file == 'image.png':
                        rel_path = os.path.relpath(root, posts_path)
                        # è®¡ç®—æ·±åº¦ï¼šåªæœ‰ä¸€çº§è·¯å¾„åˆ†éš”ç¬¦è¡¨ç¤ºç›´æ¥åœ¨ posts_path ä¸‹
                        if os.sep not in rel_path:  # ç›´æ¥åœ¨æŸä¸ªå­ç›®å½•ä¸‹ï¼Œæ²¡æœ‰è¿›ä¸€æ­¥çš„åµŒå¥—
                            print(f"[å›¾ç‰‡è·³è¿‡] {file} (é›†åˆå°é¢ï¼Œä¸è¿ç§»)")
                            continue

                    old_path = os.path.join(root, file)

                    # è®¡ç®—æ–°æ–‡ä»¶åï¼ˆå¤„ç†å†²çªï¼‰
                    new_filename = self._get_unique_filename(
                        images_dir, file, old_path, posts_path)
                    new_path = os.path.join(images_dir, new_filename)

                    try:
                        # ç§»åŠ¨æ–‡ä»¶
                        shutil.move(old_path, new_path)

                        # è®°å½•æ˜ å°„å…³ç³»ï¼ˆç”¨äºæ›´æ–° md æ–‡ä»¶ä¸­çš„å›¾ç‰‡é“¾æ¥ï¼‰
                        relative_old_path = os.path.relpath(
                            old_path, posts_path)
                        image_map[file] = new_filename  # åŸå§‹æ–‡ä»¶å -> æ–°æ–‡ä»¶å

                        print(f"[å›¾ç‰‡è¿ç§»] {file} -> {new_filename}")
                        migrated_count += 1
                    except Exception as e:
                        print(f"[å›¾ç‰‡é”™è¯¯] {file}: {e}")

        # ç¬¬äºŒæ­¥ï¼šæ›´æ–° md æ–‡ä»¶ä¸­çš„å›¾ç‰‡é“¾æ¥
        self._update_image_links_in_md(posts_path, image_map)

        return f"å·²è¿ç§» {migrated_count} å¼ å›¾ç‰‡åˆ° Images ç›®å½•"

    def _reorganize_markdown_files(self, posts_path: str) -> str:
        """å°†ç¬¬äºŒå±‚çš„ md æ–‡ä»¶ç§»åˆ°ç¬¬ä¸€å±‚ï¼ˆCollection ç›®å½•ï¼‰"""
        reorganized_count = 0

        # éå†ç¬¬ä¸€å±‚ç›®å½•ï¼ˆCollectionï¼‰
        for collection in os.listdir(posts_path):
            collection_path = os.path.join(posts_path, collection)

            # è·³è¿‡ç‰¹æ®Šç›®å½•å’Œæ–‡ä»¶
            if not os.path.isdir(collection_path) or collection in ['Images', 'Markdowns']:
                continue

            # éå†ç¬¬äºŒå±‚ç›®å½•
            for second_level in os.listdir(collection_path):
                second_level_path = os.path.join(collection_path, second_level)

                if not os.path.isdir(second_level_path):
                    continue

                # æŸ¥æ‰¾è¯¥ç›®å½•ä¸­çš„ .md æ–‡ä»¶
                for file in os.listdir(second_level_path):
                    if file.endswith('.md'):
                        old_path = os.path.join(second_level_path, file)
                        new_path = os.path.join(collection_path, file)

                        try:
                            # å¤„ç†åç§°å†²çª
                            if os.path.exists(new_path):
                                # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
                                name, ext = os.path.splitext(file)
                                counter = 1
                                while os.path.exists(new_path):
                                    new_path = os.path.join(
                                        collection_path, f"{name}-{counter}{ext}")
                                    counter += 1

                            # ç§»åŠ¨æ–‡ä»¶
                            shutil.move(old_path, new_path)
                            print(f"[æ–‡ä»¶æ•´ç†] {file} å·²ç§»åŠ¨åˆ° {collection}/")
                            reorganized_count += 1
                        except Exception as e:
                            print(f"[æ–‡ä»¶æ•´ç†é”™è¯¯] {file}: {e}")

        return f"å·²æ•´ç† {reorganized_count} ä¸ª markdown æ–‡ä»¶"

    def _cleanup_empty_directories(self, posts_path: str) -> str:
        """åˆ é™¤æ‰€æœ‰ç©ºçš„ç¬¬äºŒå±‚æ–‡ä»¶å¤¹"""
        deleted_count = 0

        # éå†ç¬¬ä¸€å±‚ç›®å½•ï¼ˆCollectionï¼‰
        for collection in os.listdir(posts_path):
            collection_path = os.path.join(posts_path, collection)

            # è·³è¿‡ç‰¹æ®Šç›®å½•å’Œæ–‡ä»¶
            if not os.path.isdir(collection_path) or collection in ['Images', 'Markdowns']:
                continue

            # éå†ç¬¬äºŒå±‚ç›®å½•
            second_level_dirs = []
            for second_level in os.listdir(collection_path):
                second_level_path = os.path.join(collection_path, second_level)

                if os.path.isdir(second_level_path):
                    second_level_dirs.append((second_level, second_level_path))

            # åˆ é™¤è¿™äº›ç¬¬äºŒå±‚ç›®å½•ï¼ˆæ— è®ºæ˜¯å¦ä¸ºç©ºï¼‰
            for dirname, dirpath in second_level_dirs:
                try:
                    # é€’å½’åˆ é™¤æ•´ä¸ªç›®å½•
                    shutil.rmtree(dirpath)
                    print(f"[åˆ é™¤æ–‡ä»¶å¤¹] {collection}/{dirname} å·²åˆ é™¤")
                    deleted_count += 1
                except Exception as e:
                    print(f"[åˆ é™¤é”™è¯¯] {collection}/{dirname}: {e}")

        return f"å·²åˆ é™¤ {deleted_count} ä¸ªç¬¬äºŒå±‚æ–‡ä»¶å¤¹"

    def _get_unique_filename(self, images_dir: str, filename: str, old_path: str, posts_path: str) -> str:
        """ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶åï¼Œå¤„ç†å†²çª"""
        target_path = os.path.join(images_dir, filename)

        # å¦‚æœæ²¡æœ‰å†²çªï¼Œç›´æ¥ä½¿ç”¨åŸæ–‡ä»¶å
        if not os.path.exists(target_path):
            return filename

        # æœ‰å†²çªï¼Œç”Ÿæˆæ–°åç§°ï¼šåœ¨æ‰©å±•åå‰æ·»åŠ å‰ç¼€
        # å‰ç¼€æ ¼å¼ï¼šCollection-ArticleFolder-
        # ä¾‹å¦‚ï¼šCode-MyArticle-image.png

        try:
            # è·å–æ–‡ç« æ‰€åœ¨çš„ç›®å½•ä¿¡æ¯
            rel_path = os.path.relpath(old_path, posts_path)
            path_parts = rel_path.split(os.sep)

            # path_parts ç»“æ„ï¼š
            # ['Collection', 'ArticleFolder', 'image.png'] æˆ–
            # ['Markdowns', 'image.png']

            if len(path_parts) >= 3:
                # æœ‰ Collection å’Œ ArticleFolder
                collection = path_parts[0]
                article_folder = path_parts[1]
                prefix = f"{collection}-{article_folder}-"
            elif len(path_parts) == 2 and path_parts[0] != 'Markdowns':
                # ç›´æ¥åœ¨ Posts ä¸‹çš„æŸä¸ªæ–‡ä»¶å¤¹ä¸­
                prefix = f"{path_parts[0]}-"
            else:
                # Markdowns ç›®å½•ä¸­çš„æ–‡ä»¶ï¼Œä½¿ç”¨è¾ƒçŸ­çš„å‰ç¼€
                prefix = "markdown-"

            # åˆ†ç¦»æ–‡ä»¶åå’Œæ‰©å±•å
            name, ext = os.path.splitext(filename)
            new_filename = prefix + filename

            # ç»§ç»­æ£€æŸ¥æ–°åç§°æ˜¯å¦å­˜åœ¨å†²çª
            counter = 1
            while os.path.exists(os.path.join(images_dir, new_filename)):
                new_filename = f"{prefix}{name}-{counter}{ext}"
                counter += 1

            return new_filename
        except Exception as e:
            # å¦‚æœå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨æ—¶é—´æˆ³
            import time
            timestamp = int(time.time())
            name, ext = os.path.splitext(filename)
            return f"{name}-{timestamp}{ext}"

    def _update_image_links_in_md(self, posts_path: str, image_map: dict) -> None:
        """æ›´æ–° md æ–‡ä»¶ä¸­çš„å›¾ç‰‡é“¾æ¥"""
        if not image_map:
            return

        print("[å›¾ç‰‡é“¾æ¥] å¼€å§‹æ›´æ–° md æ–‡ä»¶ä¸­çš„å›¾ç‰‡é“¾æ¥...")

        updated_count = 0

        # éå†æ‰€æœ‰ md æ–‡ä»¶
        for root, dirs, files in os.walk(posts_path):
            for file in files:
                if file.endswith('.md'):
                    md_path = os.path.join(root, file)

                    try:
                        with open(md_path, 'r', encoding='utf-8') as f:
                            content = f.read()

                        original_content = content

                        # æ›´æ–°æ‰€æœ‰å›¾ç‰‡é“¾æ¥
                        for old_name, new_name in image_map.items():
                            # åŒ¹é…å¤šç§å›¾ç‰‡é“¾æ¥æ ¼å¼
                            # ![alt](./image.png) æˆ– ![alt](image.png) æˆ– ![alt](../folder/image.png) ç­‰

                            # æ„å»ºæ­£åˆ™è¡¨è¾¾å¼æ¥åŒ¹é…åŒ…å«åŸæ–‡ä»¶åçš„é“¾æ¥
                            patterns = [
                                # å½¢å¼ 1: ![...](./filename)
                                rf"(\!\[.*?\]\(\.\/[^)]*){re.escape(old_name)}",
                                # å½¢å¼ 2: ![...](...filename) - ä»»ä½•åŒ…å«è·¯å¾„çš„
                                rf"(\!\[.*?\]\([^)]*\/{re.escape(old_name)})",
                                # å½¢å¼ 3: ![...](filename) - ç›´æ¥æ–‡ä»¶å
                                rf"(\!\[.*?\]\(){re.escape(old_name)}(\))",
                                # å½¢å¼ 4: å…¶ä»–å¯èƒ½çš„å¼•ç”¨æ ¼å¼
                                rf"(\[.*?\]\([^)]*\/{re.escape(old_name)})",
                            ]

                            for pattern in patterns:
                                # åŒ¹é…å¹¶æ›¿æ¢
                                matches = list(re.finditer(pattern, content))
                                for match in matches:
                                    if old_name in match.group(0):
                                        # æ›¿æ¢ä¸ºæ–°çš„æ–‡ä»¶åï¼ˆä¿æŒåŸæœ‰çš„æ ¼å¼ï¼‰
                                        new_link = match.group(
                                            0).replace(old_name, new_name)
                                        content = content.replace(
                                            match.group(0), new_link, 1)

                        # å¦‚æœå†…å®¹æœ‰å˜åŒ–ï¼Œå†™å›æ–‡ä»¶
                        if content != original_content:
                            with open(md_path, 'w', encoding='utf-8') as f:
                                f.write(content)
                            print(f"[å›¾ç‰‡é“¾æ¥] å·²æ›´æ–°: {file}")
                            updated_count += 1

                    except Exception as e:
                        print(f"[å›¾ç‰‡é“¾æ¥é”™è¯¯] {file}: {e}")

        print(f"[å›¾ç‰‡é“¾æ¥] å·²æ›´æ–° {updated_count} ä¸ª md æ–‡ä»¶ä¸­çš„å›¾ç‰‡é“¾æ¥")

    def _migrate_file(self, file_path: str) -> bool:
        """è¿ç§»å•ä¸ªæ–‡ä»¶ï¼Œè¿”å›æ˜¯å¦è¿ç§»è¿‡"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # æå– metadata éƒ¨åˆ†
        metadata_match = re.match(r'^---\n([\s\S]*?)\n---\n', content)
        if not metadata_match:
            return False  # æ ¼å¼ä¸æ­£ç¡®

        metadata_text = metadata_match.group(1)
        body = content[metadata_match.end():]

        # è§£æ metadataï¼ˆæ”¯æŒ YAML æ ¼å¼ï¼‰
        metadata = self._parse_yaml_metadata(metadata_text)

        # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯ KMBlog æ ¼å¼ï¼ˆæœ‰ pre æˆ– img å­—æ®µï¼‰
        if 'pre' in metadata or 'img' in metadata or isinstance(metadata.get('tags'), list) and len(metadata.get('tags', [])) > 0 and isinstance(metadata['tags'][0], dict):
            return False  # å·²ç»æ˜¯æ–°æ ¼å¼

        # è½¬æ¢æ ¼å¼
        new_metadata = self._convert_metadata(metadata)

        # æ„å»ºæ–°çš„æ–‡ä»¶å†…å®¹
        new_content = self._build_new_content(new_metadata, body)

        # å†™å›æ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(new_content)

        return True

    def _parse_yaml_metadata(self, metadata_text: str) -> dict:
        """è§£æ YAML æ ¼å¼çš„ metadata"""
        metadata = {}
        lines = metadata_text.split('\n')
        current_key = None
        current_list = []

        for line in lines:
            line = line.rstrip()

            # æ£€æŸ¥æ˜¯å¦æ˜¯é”®å€¼å¯¹
            if ': ' in line and not line.startswith(' '):
                # ä¿å­˜å‰ä¸€ä¸ªåˆ—è¡¨
                if current_key and current_list:
                    metadata[current_key] = current_list
                    current_list = []

                key, value = line.split(': ', 1)
                key = key.strip()
                value = value.strip()

                # å¤„ç†æ•°ç»„æ ¼å¼ [a, b, c]
                if value.startswith('[') and value.endswith(']'):
                    array_str = value[1:-1]
                    metadata[key] = [item.strip().strip('\'"')
                                     for item in array_str.split(',')]
                else:
                    metadata[key] = value
                current_key = None

            # æ£€æŸ¥æ˜¯å¦æ˜¯åˆ—è¡¨é¡¹ - key:
            elif ': ' in line and not line.startswith(' '):
                # ä¿å­˜å‰ä¸€ä¸ªåˆ—è¡¨
                if current_key and current_list:
                    metadata[current_key] = current_list
                    current_list = []

                key, value = line.split(': ', 1)
                metadata[key.strip()] = value.strip()
                current_key = None

            # æ£€æŸ¥æ˜¯å¦æ˜¯ YAML åˆ—è¡¨å¼€å§‹
            elif line.endswith(':') and not line.startswith(' '):
                key = line[:-1].strip()
                if current_key and current_list:
                    metadata[current_key] = current_list
                current_key = key
                current_list = []

            # æ£€æŸ¥æ˜¯å¦æ˜¯åˆ—è¡¨é¡¹ - ç©ºæ ¼å¼€å¤´
            elif line.startswith('- ') and current_key:
                item = line[2:].strip().strip('\'"')
                current_list.append(item)

        # ä¿å­˜æœ€åä¸€ä¸ªåˆ—è¡¨
        if current_key and current_list:
            metadata[current_key] = current_list

        return metadata

    def _convert_metadata(self, metadata: dict) -> dict:
        """è½¬æ¢ metadata æ ¼å¼"""
        new_metadata = {}

        # ä¿ç•™åŸºæœ¬å­—æ®µ
        for key in ['title', 'date']:
            if key in metadata:
                new_metadata[key] = metadata[key]

        # è½¬æ¢ tags - ç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼
        if 'tags' in metadata:
            tags = metadata['tags']
            if isinstance(tags, str):
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æ
                if tags.startswith('[') and tags.endswith(']'):
                    tags = [t.strip().strip('\'"')
                            for t in tags[1:-1].split(',')]
                else:
                    tags = [tags]
            elif not isinstance(tags, list):
                tags = [str(tags)]
            new_metadata['tags'] = tags
        else:
            new_metadata['tags'] = []

        # è½¬æ¢ categories
        if 'categories' in metadata:
            categories = metadata['categories']
            if isinstance(categories, str):
                if categories.startswith('[') and categories.endswith(']'):
                    categories = [c.strip().strip('\'"')
                                  for c in categories[1:-1].split(',')]
                else:
                    categories = [categories]
            elif not isinstance(categories, list):
                categories = [str(categories)]
            new_metadata['categories'] = categories
        else:
            new_metadata['categories'] = []

        # æ·»åŠ æ–°å­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if 'pre' not in new_metadata:
            new_metadata['pre'] = ''
        if 'img' not in new_metadata:
            new_metadata['img'] = ''

        return new_metadata

    def _build_new_content(self, metadata: dict, body: str) -> str:
        """æ„å»ºæ–°æ ¼å¼çš„æ–‡ä»¶å†…å®¹"""
        lines = ['---']

        # å†™å…¥å„å­—æ®µ
        for key in ['title', 'date']:
            if key in metadata:
                lines.append(f"{key}: {metadata[key]}")

        # å†™å…¥ tagsï¼ˆåˆ—è¡¨æ ¼å¼ï¼‰
        if 'tags' in metadata and metadata['tags']:
            lines.append('tags:')
            for tag in metadata['tags']:
                lines.append(f'- {tag}')
        else:
            lines.append('tags:')

        # å†™å…¥ categoriesï¼ˆåˆ—è¡¨æ ¼å¼ï¼‰
        if 'categories' in metadata and metadata['categories']:
            lines.append('categories:')
            for cat in metadata['categories']:
                lines.append(f'- {cat}')
        else:
            lines.append('categories:')

        # å†™å…¥ pre å’Œ img
        lines.append(f"pre: {metadata.get('pre', '')}")
        lines.append(f"img: {metadata.get('img', '')}")

        lines.append('---')
        lines.append(body)

        return '\n'.join(lines)


class StartEditor(Command):
    """å¯åŠ¨æœ¬åœ°Markdownç¼–è¾‘å™¨"""
    description = "Starts the local Markdown editor with FastAPI backend and opens it in browser"

    def execute(self):
        """
        å¯åŠ¨ç¼–è¾‘å™¨çš„ä¸»è¦é€»è¾‘:
        1. åˆ›å»ºä¸´æ—¶æ–‡ä»¶å­˜å‚¨æœåŠ¡å™¨ä¿¡æ¯
        2. å¯åŠ¨FastAPIæœåŠ¡å™¨è¿›ç¨‹
        3. è¯»å–ç«¯å£å’Œtokenä¿¡æ¯
        4. åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ç¼–è¾‘å™¨URL
        """
        import subprocess
        import webbrowser
        import time
        import tempfile

        # è·å–editor_server.pyçš„è·¯å¾„
        server_script = os.path.join(
            os.path.dirname(__file__),
            'editor_server.py'
        )

        if not os.path.exists(server_script):
            return f"Error: editor_server.py not found at {server_script}"

        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶å­˜å‚¨æœåŠ¡å™¨ä¿¡æ¯
        info_file = tempfile.NamedTemporaryFile(
            mode='w',
            delete=False,
            suffix='.json'
        )
        info_path = info_file.name
        info_file.close()

        try:
            # å¯åŠ¨FastAPIæœåŠ¡å™¨,ä¼ é€’ä¿¡æ¯æ–‡ä»¶è·¯å¾„
            print("Starting Markdown Editor server...")
            server_process = subprocess.Popen(
                ["python", server_script, "--info-file", info_path],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                creationflags=subprocess.CREATE_NEW_CONSOLE if os.name == 'nt' else 0
            )

            # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨å¹¶å†™å…¥ä¿¡æ¯
            max_wait = 10
            server_info = None

            for i in range(max_wait):
                time.sleep(0.5)
                if os.path.exists(info_path) and os.path.getsize(info_path) > 0:
                    try:
                        with open(info_path, 'r') as f:
                            server_info = json.load(f)
                        break
                    except json.JSONDecodeError:
                        # æ–‡ä»¶å¯èƒ½è¿˜åœ¨å†™å…¥ä¸­
                        continue

            if not server_info:
                server_process.terminate()
                return "Error: Failed to start server - timeout waiting for server info"

            port = server_info['port']
            token = server_info['token']

            # æ‰“å¼€æµè§ˆå™¨,URLä¸­åŒ…å«tokenå’Œç«¯å£
            editor_url = f"http://localhost:5173/#/editor?token={token}&api_port={port}"
            print(f"\nOpening editor in browser: {editor_url}")
            print(f"Server running on port: {port}")
            print(f"Auth token: {token[:16]}...")
            print("\nNote: The editor server is running in a separate console window.")
            print("Close that window or press Ctrl+C there to stop the server.")

            webbrowser.open(editor_url)

            return f"Editor started successfully!\nServer: http://127.0.0.1:{port}\nEditor: {editor_url}\n\nThe server is running in a separate console window."

        except Exception as e:
            return f"Error starting editor: {str(e)}"
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                if os.path.exists(info_path):
                    os.unlink(info_path)
            except:
                pass


# å¯¼å…¥ GitHub ç›¸å…³å‘½ä»¤
